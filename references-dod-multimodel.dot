digraph SpecDoDMultiModel {
    graph [
        goal="Converge libs/sdk-rust/ to match the reference implementations in Go (sdk-go) and TypeScript (sdk-typescript). Do NOT modify generated API clients (api-client-rust, toolbox-api-client-rust). Only modify code under libs/sdk-rust/. Where Go and TypeScript diverge, use judgement on which to follow. Uses multi-model consensus: Opus 4.6 and GPT-5.2 compete on audits and planning, GPT-5.2-codex and Opus 4.6 alternate on implementation.",
        default_max_retry="3",
        retry_target="triage_merge",
        default_fidelity="full",
        model_stylesheet="
            * { llm_model: claude-opus-4-6; llm_provider: anthropic; }
            .opus   { llm_model: claude-opus-4-6; llm_provider: anthropic; reasoning_effort: high; }
            .gpt    { llm_model: gpt-5.2;         llm_provider: openai;    reasoning_effort: high; }
            .codex  { llm_model: gpt-5.2-codex;   llm_provider: openai;    reasoning_effort: high; }
            .merge  { llm_model: claude-opus-4-6;  llm_provider: anthropic; reasoning_effort: high; }
        "
    ]

    start [shape=Mdiamond]
    exit  [shape=Msquare]

    /*========================================================================
     * PHASE 1 — Dual Independent Audits (fidelity-isolated)
     *
     * Each model independently audits the Rust SDK against Go and TypeScript
     * reference implementations. Audit nodes use fidelity="truncate" so they
     * only see the graph goal and NOT each other's responses — prevents
     * anchoring bias. Full responses are still stored as response.<node_id>
     * for later use.
     *
     * Reference paths:
     *   Go SDK:         /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/
     *   TypeScript SDK: /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/
     *   Rust SDK:       libs/sdk-rust/src/
     *
     * Module mapping:
     *   client.rs           ↔ client.go, Daytona.ts
     *   config.rs           ↔ (in client.go), (in Daytona.ts)
     *   error.rs            ↔ (in errors/), (in errors/)
     *   types.rs            ↔ (in types/), (in types/)
     *   sandbox.rs          ↔ sandbox.go, Sandbox.ts
     *   filesystem.rs       ↔ filesystem.go, FileSystem.ts
     *   git.rs              ↔ git.go, Git.ts
     *   process.rs          ↔ process.go, Process.ts
     *   code_interpreter.rs ↔ code_interpreter.go, CodeInterpreter.ts
     *   computer_use.rs     ↔ computer_use.go, ComputerUse.ts
     *   image.rs            ↔ image.go, Image.ts
     *   snapshot.rs         ↔ snapshot.go, Snapshot.ts
     *   volume.rs           ↔ volume.go, Volume.ts
     *   (missing)           ↔ object_storage.go, ObjectStorage.ts
     *   (missing)           ↔ pty_handle.go, PtyHandle.ts
     *======================================================================*/

    audit_opus [
        label="Opus: Audit Full SDK",
        shape=box,
        class="opus",
        fidelity="truncate",
        prompt="Compare the entire Rust SDK against both reference implementations. Read all of these files:

Rust (our implementation):
- libs/sdk-rust/src/lib.rs
- libs/sdk-rust/src/client.rs
- libs/sdk-rust/src/config.rs
- libs/sdk-rust/src/error.rs
- libs/sdk-rust/src/types.rs
- libs/sdk-rust/src/sandbox.rs
- libs/sdk-rust/src/snapshot.rs
- libs/sdk-rust/src/volume.rs
- libs/sdk-rust/src/image.rs
- libs/sdk-rust/src/filesystem.rs
- libs/sdk-rust/src/git.rs
- libs/sdk-rust/src/process.rs
- libs/sdk-rust/src/code_interpreter.rs
- libs/sdk-rust/src/computer_use.rs

Go reference:
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/client.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/sandbox.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/snapshot.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/volume.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/image.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/filesystem.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/git.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/process.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/code_interpreter.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/computer_use.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/object_storage.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/pty_handle.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/options/ (all files)
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/types/ (all files)
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/errors/ (all files)

TypeScript reference:
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/Daytona.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/Sandbox.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/Snapshot.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/Volume.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/Image.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/FileSystem.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/Git.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/Process.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/CodeInterpreter.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/ComputerUse.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/ObjectStorage.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/PtyHandle.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/types/ (all files)
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/errors/ (all files)
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/index.ts

Where Go and TypeScript diverge, use your judgement on which to follow.

For each Rust module, compare against BOTH references and check:
1. PUBLIC API SURFACE — are all public methods/functions present? Any missing?
2. METHOD SIGNATURES — do parameters and return types align (accounting for language idioms)?
3. BEHAVIOR — does the logic match? Are there behavioral differences?
4. ERROR HANDLING — are the same error cases covered?
5. MISSING MODULES — note any types/exports present in Go/TS but absent in Rust (e.g. object_storage, pty_handle)

For each missing module (object_storage, pty_handle), document:
1. What public API it exposes (methods, types)
2. What generated API client methods it wraps
3. How complex it would be to implement

Also check: does the Rust SDK lib.rs export everything it should? Compare with the TypeScript index.ts.

Respond with ONLY a JSON object (no prose) -- don't write it out as a file:
{
  \"model\": \"opus\",
  \"areas\": {
    \"core\": {
      \"modules\": {
        \"client\": {
          \"missing_methods\": [ {\"name\": \"...\", \"in_go\": true/false, \"in_ts\": true/false, \"description\": \"...\"} ],
          \"signature_mismatches\": [ {\"method\": \"...\", \"issue\": \"...\"} ],
          \"behavior_gaps\": [ {\"description\": \"...\", \"severity\": \"high|medium|low\"} ]
        },
        \"config\": { ... },
        \"error\": { ... },
        \"types\": { ... }
      }
    },
    \"sandbox_lifecycle\": {
      \"modules\": {
        \"sandbox\": { ... },
        \"snapshot\": { ... },
        \"volume\": { ... },
        \"image\": { ... }
      }
    },
    \"services\": {
      \"modules\": {
        \"filesystem\": { ... },
        \"git\": { ... },
        \"process\": { ... },
        \"code_interpreter\": { ... },
        \"computer_use\": { ... }
      }
    },
    \"missing_modules\": {
      \"modules\": {
        \"object_storage\": {
          \"methods\": [ {\"name\": \"...\", \"description\": \"...\", \"wraps_api\": \"...\"} ],
          \"types\": [ \"...\" ],
          \"complexity\": \"high|medium|low\",
          \"notes\": \"...\"
        },
        \"pty_handle\": { ... }
      },
      \"missing_exports\": [ \"...\" ]
    }
  },
  \"total_gaps\": N,
  \"high_severity\": M,
  \"medium_severity\": K,
  \"low_severity\": L
}

Be thorough. Check every public method and type."
    ]

    audit_gpt [
        label="GPT-5.2: Audit Full SDK",
        shape=box,
        class="gpt",
        fidelity="truncate",
        prompt="Compare the entire Rust SDK against both reference implementations. Read all of these files:

Rust (our implementation):
- libs/sdk-rust/src/lib.rs
- libs/sdk-rust/src/client.rs
- libs/sdk-rust/src/config.rs
- libs/sdk-rust/src/error.rs
- libs/sdk-rust/src/types.rs
- libs/sdk-rust/src/sandbox.rs
- libs/sdk-rust/src/snapshot.rs
- libs/sdk-rust/src/volume.rs
- libs/sdk-rust/src/image.rs
- libs/sdk-rust/src/filesystem.rs
- libs/sdk-rust/src/git.rs
- libs/sdk-rust/src/process.rs
- libs/sdk-rust/src/code_interpreter.rs
- libs/sdk-rust/src/computer_use.rs

Go reference:
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/client.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/sandbox.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/snapshot.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/volume.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/image.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/filesystem.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/git.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/process.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/code_interpreter.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/computer_use.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/object_storage.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/pty_handle.go
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/options/ (all files)
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/types/ (all files)
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/errors/ (all files)

TypeScript reference:
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/Daytona.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/Sandbox.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/Snapshot.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/Volume.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/Image.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/FileSystem.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/Git.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/Process.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/CodeInterpreter.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/ComputerUse.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/ObjectStorage.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/PtyHandle.ts
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/types/ (all files)
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/errors/ (all files)
- /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/index.ts

Where Go and TypeScript diverge, use your judgement on which to follow.

For each Rust module, compare against BOTH references and check:
1. PUBLIC API SURFACE — are all public methods/functions present? Any missing?
2. METHOD SIGNATURES — do parameters and return types align (accounting for language idioms)?
3. BEHAVIOR — does the logic match? Are there behavioral differences?
4. ERROR HANDLING — are the same error cases covered?
5. MISSING MODULES — note any types/exports present in Go/TS but absent in Rust (e.g. object_storage, pty_handle)

For each missing module (object_storage, pty_handle), document:
1. What public API it exposes (methods, types)
2. What generated API client methods it wraps
3. How complex it would be to implement

Also check: does the Rust SDK lib.rs export everything it should? Compare with the TypeScript index.ts.

Respond with ONLY a JSON object (no prose) -- don't write it out as a file:
{
  \"model\": \"gpt-5.2\",
  \"areas\": {
    \"core\": {
      \"modules\": {
        \"client\": {
          \"missing_methods\": [ {\"name\": \"...\", \"in_go\": true/false, \"in_ts\": true/false, \"description\": \"...\"} ],
          \"signature_mismatches\": [ {\"method\": \"...\", \"issue\": \"...\"} ],
          \"behavior_gaps\": [ {\"description\": \"...\", \"severity\": \"high|medium|low\"} ]
        },
        \"config\": { ... },
        \"error\": { ... },
        \"types\": { ... }
      }
    },
    \"sandbox_lifecycle\": {
      \"modules\": {
        \"sandbox\": { ... },
        \"snapshot\": { ... },
        \"volume\": { ... },
        \"image\": { ... }
      }
    },
    \"services\": {
      \"modules\": {
        \"filesystem\": { ... },
        \"git\": { ... },
        \"process\": { ... },
        \"code_interpreter\": { ... },
        \"computer_use\": { ... }
      }
    },
    \"missing_modules\": {
      \"modules\": {
        \"object_storage\": {
          \"methods\": [ {\"name\": \"...\", \"description\": \"...\", \"wraps_api\": \"...\"} ],
          \"types\": [ \"...\" ],
          \"complexity\": \"high|medium|low\",
          \"notes\": \"...\"
        },
        \"pty_handle\": { ... }
      },
      \"missing_exports\": [ \"...\" ]
    }
  },
  \"total_gaps\": N,
  \"high_severity\": M,
  \"medium_severity\": K,
  \"low_severity\": L
}

Be thorough. Check every public method and type."
    ]

    /*========================================================================
     * PHASE 2 — Cross-Critique (fidelity=full to see all response.* keys)
     *
     * Each model reviews the other's audit. Like megaplan's Compete phase:
     * independent work first, then adversarial review.
     *======================================================================*/

    critique_by_gpt [
        label="GPT-5.2: Critique Opus Audit",
        shape=box,
        class="gpt",
        fidelity="full",
        prompt="You have both audit reports available in context. The full outputs are in these context keys:

OPUS AUDIT:
- response.audit_opus — Opus's full SDK comparison audit

GPT AUDIT (your own):
- response.audit_gpt — your full SDK comparison audit

Compare them item by item. For every gap where the two models DISAGREE (one flags it, the other doesn't), re-read the relevant reference files and Rust source to determine who is correct.

Also identify items that one model flagged but the other missed entirely.

Respond with JSON (not by writing out a file):
{
  \"agreements\": { \"both_flagged\": N, \"both_clear\": N },
  \"disagreements\": [
    {
      \"area\": \"...\", \"module\": \"...\", \"description\": \"...\",
      \"opus_says\": \"gap|clear\", \"gpt_says\": \"gap|clear\",
      \"verdict\": \"gap|clear\",
      \"reasoning\": \"...\"
    }
  ],
  \"missed_by_opus\": [ {\"area\": \"...\", \"module\": \"...\", \"description\": \"...\", \"reason\": \"...\"} ],
  \"missed_by_gpt\": [ {\"area\": \"...\", \"module\": \"...\", \"description\": \"...\", \"reason\": \"...\"} ]
}

Be rigorous. When in doubt, flag it as a gap — strictness prevents false confidence."
    ]

    critique_by_opus [
        label="Opus: Critique GPT-5.2 Audit",
        shape=box,
        class="opus",
        fidelity="full",
        prompt="You have both audit reports available in context. The full outputs are in these context keys:

GPT AUDIT:
- response.audit_gpt — GPT-5.2's full SDK comparison audit

OPUS AUDIT (your own):
- response.audit_opus — your full SDK comparison audit

Compare them item by item. For every gap where the two models DISAGREE (one flags it, the other doesn't), re-read the relevant reference files and Rust source to determine who is correct.

Also identify items that one model flagged but the other missed entirely.

Respond with JSON (not by writing out a file):
{
  \"agreements\": { \"both_flagged\": N, \"both_clear\": N },
  \"disagreements\": [
    {
      \"area\": \"...\", \"module\": \"...\", \"description\": \"...\",
      \"opus_says\": \"gap|clear\", \"gpt_says\": \"gap|clear\",
      \"verdict\": \"gap|clear\",
      \"reasoning\": \"...\"
    }
  ],
  \"missed_by_opus\": [ {\"area\": \"...\", \"module\": \"...\", \"description\": \"...\", \"reason\": \"...\"} ],
  \"missed_by_gpt\": [ {\"area\": \"...\", \"module\": \"...\", \"description\": \"...\", \"reason\": \"...\"} ]
}

Be rigorous. When in doubt, flag it as a gap — strictness prevents false confidence."
    ]

    /*========================================================================
     * PHASE 3 — Audit Consensus
     *
     * Merge all findings into a single agreed-upon truth.
     * Like megaplan's Merge phase: best ideas from both, disagreements resolved.
     *======================================================================*/

    audit_consensus [
        label="Merge: Audit Consensus",
        shape=box,
        class="merge",
        fidelity="full",
        prompt="You have all prior audit and critique outputs in context. The key inputs are:

TWO AUDIT REPORTS (context keys response.audit_opus, response.audit_gpt)

TWO CROSS-CRITIQUES (context keys response.critique_by_gpt, response.critique_by_opus)

Produce a single definitive audit result. Resolution rules:
1. If BOTH models agree on a gap → include it
2. If BOTH models agree something is clear → exclude it
3. If they DISAGREE, use the cross-critique verdicts. If the critiques also disagree, re-read the reference files and Rust code yourself and make the call. When in doubt, include it as a gap.
4. Include any items that were missed by one model but caught by the other.

Respond with JSON (not by writing out a file):
{
  \"areas\": {
    \"core\": { ... },
    \"sandbox_lifecycle\": { ... },
    \"services\": { ... },
    \"missing_modules\": { ... }
  },
  \"consensus_total_gaps\": N,
  \"consensus_high_severity\": M,
  \"consensus_medium_severity\": K,
  \"consensus_low_severity\": L,
  \"disagreements_resolved\": N,
  \"all_gaps\": [ {\"area\": \"...\", \"module\": \"...\", \"description\": \"...\", \"severity\": \"high|medium|low\", \"agreed_by\": \"both|opus_only|gpt_only|resolved\"} ]
}"
    ]

    /*========================================================================
     * PHASE 4 — Dual Triage
     *
     * Both models independently prioritize the gaps, then merge.
     * Different models weight different risks differently — consensus is stronger.
     *======================================================================*/

    triage_opus [
        label="Opus: Triage & Prioritize",
        shape=box,
        class="opus",
        fidelity="full",
        prompt="The consensus audit results are in context key response.audit_consensus. Parse the all_gaps list from that JSON and triage every gap between the Rust SDK and the Go/TypeScript reference implementations.

Group gaps into:
1. IMPLEMENTABLE — can be fixed by writing/modifying Rust code in libs/sdk-rust/src/ (adding methods, fixing signatures, aligning behavior)
2. STRUCTURAL — requires new files or significant architecture changes (e.g., adding entirely new modules like object_storage.rs, pty_handle.rs)
3. DEFERRED — requires external resources or changes outside libs/sdk-rust/ that cannot be done (e.g., changes to generated API clients, runtime testing with a real Daytona instance)

For each IMPLEMENTABLE item, identify the exact file(s) to modify and briefly describe the fix. Rank them by impact (most important first).

IMPORTANT CONSTRAINTS:
- Do NOT propose changes to libs/api-client-rust/ or libs/toolbox-api-client-rust/ — those are generated from OpenAPI specs
- Only propose changes to files under libs/sdk-rust/

Respond with JSON (not by writing out a file):
{
  \"model\": \"opus\",
  \"total_gaps\": N,
  \"implementable\": [ {\"rank\": 1, \"area\": \"...\", \"module\": \"...\", \"description\": \"...\", \"severity\": \"high|medium|low\", \"files\": [\"...\"], \"fix\": \"...\", \"impact\": \"high|medium|low\"} ],
  \"structural\": [ {\"area\": \"...\", \"module\": \"...\", \"description\": \"...\", \"severity\": \"high|medium|low\", \"fix\": \"...\"} ],
  \"deferred\": [ {\"area\": \"...\", \"module\": \"...\", \"description\": \"...\", \"reason\": \"...\"} ]
}"
    ]

    triage_gpt [
        label="GPT-5.2: Triage & Prioritize",
        shape=box,
        class="gpt",
        fidelity="full",
        prompt="The consensus audit results are in context key response.audit_consensus. Parse the all_gaps list from that JSON and triage every gap between the Rust SDK and the Go/TypeScript reference implementations.

Group gaps into:
1. IMPLEMENTABLE — can be fixed by writing/modifying Rust code in libs/sdk-rust/src/ (adding methods, fixing signatures, aligning behavior)
2. STRUCTURAL — requires new files or significant architecture changes (e.g., adding entirely new modules like object_storage.rs, pty_handle.rs)
3. DEFERRED — requires external resources or changes outside libs/sdk-rust/ that cannot be done (e.g., changes to generated API clients, runtime testing with a real Daytona instance)

For each IMPLEMENTABLE item, identify the exact file(s) to modify and briefly describe the fix. Rank them by impact (most important first).

IMPORTANT CONSTRAINTS:
- Do NOT propose changes to libs/api-client-rust/ or libs/toolbox-api-client-rust/ — those are generated from OpenAPI specs
- Only propose changes to files under libs/sdk-rust/

Respond with JSON (not by writing out a file):
{
  \"model\": \"gpt-5.2\",
  \"total_gaps\": N,
  \"implementable\": [ {\"rank\": 1, \"area\": \"...\", \"module\": \"...\", \"description\": \"...\", \"severity\": \"high|medium|low\", \"files\": [\"...\"], \"fix\": \"...\", \"impact\": \"high|medium|low\"} ],
  \"structural\": [ {\"area\": \"...\", \"module\": \"...\", \"description\": \"...\", \"severity\": \"high|medium|low\", \"fix\": \"...\"} ],
  \"deferred\": [ {\"area\": \"...\", \"module\": \"...\", \"description\": \"...\", \"reason\": \"...\"} ]
}"
    ]

    triage_merge [
        label="Merge: Triage Consensus",
        shape=box,
        class="merge",
        fidelity="full",
        prompt="You have two triage reports in context: response.triage_opus and response.triage_gpt. Merge them into a single prioritized work plan.

Resolution rules:
1. If both models classify an item the same way (IMPLEMENTABLE/STRUCTURAL/DEFERRED) → keep that classification
2. If they disagree on classification → take the MORE ACTIONABLE classification (prefer IMPLEMENTABLE over STRUCTURAL over DEFERRED)
3. For ranking, average the ranks and re-sort. If one model identified files/fixes the other didn't, include all suggestions.
4. Deduplicate items that both models identified.

Respond with JSON (not by writing out a file):
{
  \"total_gaps\": N,
  \"implementable\": [ {\"area\": \"...\", \"module\": \"...\", \"description\": \"...\", \"severity\": \"high|medium|low\", \"files\": [\"...\"], \"fix\": \"...\", \"opus_rank\": N, \"gpt_rank\": N} ],
  \"structural\": [ {\"area\": \"...\", \"module\": \"...\", \"description\": \"...\", \"severity\": \"high|medium|low\", \"fix\": \"...\"} ],
  \"deferred\": [ {\"area\": \"...\", \"module\": \"...\", \"description\": \"...\", \"reason\": \"...\"} ],
  \"classification_disagreements\": N,
  \"verdict\": \"all_clear\" | \"has_fixes\" | \"only_deferred\"
}

If total_gaps == 0 or verdict == \"only_deferred\", set preferred_next_label to \"Done\".
Otherwise set preferred_next_label to \"Fix\"."
    ]

    /*========================================================================
     * PHASE 5 — Multi-Model Implementation
     *
     * Codex implements, Opus reviews and corrects, Codex validates.
     * Like megaplan's draft→critique→merge but for code.
     *======================================================================*/

    fix_codex [
        label="Codex: Implement Fixes",
        shape=box,
        class="codex",
        goal_gate=true,
        fidelity="full",
        prompt="The merged triage report is in context key response.triage_merge. It contains a prioritized list of IMPLEMENTABLE gaps between the Rust SDK and the Go/TypeScript reference implementations.

Pick the top 5 most impactful items (or all if fewer than 5) and implement fixes.

Begin by making sure the build is green with `cargo test`

For each fix:
1. Read the relevant Rust source file in libs/sdk-rust/src/
2. Read the corresponding Go and/or TypeScript reference file to understand the expected behavior
3. Implement the change to align the Rust SDK with the references
4. Write the modified file(s) -- update tests as needed
5. Verify compilation and tests pass (`cargo test`)

Where Go and TypeScript diverge, use your judgement on which to follow.

Constraints:
- Do NOT modify any files under libs/api-client-rust/ or libs/toolbox-api-client-rust/ — those are generated
- Only modify files under libs/sdk-rust/
- Keep changes focused — align with reference implementations, don't over-engineer
- Use idiomatic Rust (Result types, Option, proper error handling) — don't blindly transliterate Go/TS
- When adding methods, check if the underlying API client already exposes the needed generated methods

Respond with JSON (not by writing out a file):
{
  \"model\": \"codex\",
  \"fixes_applied\": [ {\"area\": \"...\", \"module\": \"...\", \"description\": \"...\", \"files_changed\": [\"...\"], \"reference_files\": [\"...\"]} ],
  \"count\": N,
  \"remaining_implementable\": M
}"
    ]

    review_fix_opus [
        label="Opus: Review & Fix",
        shape=box,
        class="opus",
        goal_gate=true,
        fidelity="full",
        prompt="Codex just implemented a batch of fixes to converge the Rust SDK with the Go/TypeScript references. Its report is in context key response.fix_codex.

PART A — Review Codex's work:
1. Read every file that Codex modified (check the files_changed lists in response.fix_codex)
2. For each fix, verify it actually aligns the Rust SDK with the reference implementations
3. Check for: correctness, edge cases, style consistency, missing error handling
4. Compare against the Go and TypeScript references to confirm alignment
5. If a fix is wrong or incomplete, rewrite it correctly

PART B — Implement additional fixes:
6. From the remaining IMPLEMENTABLE items (see response.triage_merge for the full list), pick up to 5 more and implement them
7. Follow the same constraints as Codex (only libs/sdk-rust/, no new deps, minimal changes, idiomatic Rust)

Respond with JSON (not by writing out a file):
{
  \"model\": \"opus\",
  \"codex_fixes_reviewed\": N,
  \"codex_fixes_correct\": N,
  \"codex_fixes_corrected\": [ {\"area\": \"...\", \"module\": \"...\", \"issue\": \"...\", \"correction\": \"...\"} ],
  \"additional_fixes\": [ {\"area\": \"...\", \"module\": \"...\", \"description\": \"...\", \"files_changed\": [\"...\"], \"reference_files\": [\"...\"]} ],
  \"total_fixes_this_round\": N,
  \"remaining_implementable\": M
}"
    ]

    review_codex [
        label="Codex: Validate All Changes",
        shape=box,
        class="codex",
        fidelity="full",
        prompt="Opus reviewed your fixes and implemented additional ones. Its report is in context key response.review_fix_opus. Your original report is in response.fix_codex.

Validate the full set of changes from this round:
1. Read every file modified in this round (check files_changed in both response.fix_codex and response.review_fix_opus)
2. Check each change for correctness: does it align the Rust SDK with the Go/TypeScript references?
3. Check for regressions: did any fix break something else?
4. Check for consistency: do all the changes work together?

Respond with JSON (not by writing out a file):
{
  \"model\": \"codex\",
  \"total_changes_reviewed\": N,
  \"all_correct\": true/false,
  \"issues_found\": [ {\"file\": \"...\", \"issue\": \"...\", \"severity\": \"critical|minor\"} ],
  \"remaining_implementable\": M
}

If issues_found contains any critical items, set preferred_next_label to \"More fixes needed\".
If remaining_implementable > 0 and no critical issues, set preferred_next_label to \"More fixes needed\".
Otherwise set preferred_next_label to \"Ready for build\"."
    ]

    /*========================================================================
     * PHASE 6 — Build Verification
     *======================================================================*/

    build_check [
        label="Build & Test",
        shape=parallelogram,
        tool_command="cd /Users/bhelmkamp/p/brynary/daytona-sdk-rust && cargo build 2>&1 && echo '---BUILD OK---' && cargo test 2>&1 && echo '---ALL TESTS PASSED---'",
        timeout="120s"
    ]

    build_fix [
        label="Opus: Fix Build Errors",
        shape=box,
        class="opus",
        fidelity="full",
        prompt="The build or tests failed. The build output is in context key tool.output. Diagnose the compilation errors or test failures and fix them.

Read the relevant source files under libs/sdk-rust/src/, identify the issue, and write corrected versions. Common issues:
- Missing use/imports
- Type mismatches with generated API client types
- Lifetime or borrow checker errors
- Missing trait implementations

IMPORTANT: Do NOT modify files under libs/api-client-rust/ or libs/toolbox-api-client-rust/.
Only fix files under libs/sdk-rust/.

Output the fixes applied and ensure the code will compile cleanly with: cargo build && cargo test"
    ]

    /*========================================================================
     * PHASE 7 — Dual Final Audit (fidelity-isolated)
     *
     * Both models independently verify the fixes worked.
     * If either model finds a remaining gap, it counts.
     *======================================================================*/

    final_audit_opus [
        label="Opus: Final Verification",
        shape=box,
        class="opus",
        fidelity="full",
        prompt="This is a verification pass. The gaps that were previously identified are listed in context key response.triage_merge (the implementable list). The fixes applied are in response.fix_codex and response.review_fix_opus.

Re-read the reference implementations for the modules that were changed:

Go:  /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/
TS:  /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/

And re-read the Rust implementation files that were changed in this iteration under libs/sdk-rust/src/.

Check ONLY the gaps that were previously identified. Have they been closed?

Respond with JSON (not by writing out a file):
{
  \"model\": \"opus\",
  \"verified_fixed\": [ {\"area\": \"...\", \"module\": \"...\", \"description\": \"...\"} ],
  \"still_failing\": [ {\"area\": \"...\", \"module\": \"...\", \"description\": \"...\", \"reason\": \"...\"} ],
  \"newly_broken\": [ ... ],
  \"remaining_total\": N
}"
    ]

    final_audit_gpt [
        label="GPT-5.2: Final Verification",
        shape=box,
        class="gpt",
        fidelity="full",
        prompt="This is a verification pass. The gaps that were previously identified are listed in context key response.triage_merge (the implementable list). The fixes applied are in response.fix_codex and response.review_fix_opus.

Re-read the reference implementations for the modules that were changed:

Go:  /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-go/pkg/daytona/
TS:  /Users/bhelmkamp/p/daytonaio/daytona/libs/sdk-typescript/src/

And re-read the Rust implementation files that were changed in this iteration under libs/sdk-rust/src/.

Check ONLY the gaps that were previously identified. Have they been closed?

Respond with JSON (not by writing out a file):
{
  \"model\": \"gpt-5.2\",
  \"verified_fixed\": [ {\"area\": \"...\", \"module\": \"...\", \"description\": \"...\"} ],
  \"still_failing\": [ {\"area\": \"...\", \"module\": \"...\", \"description\": \"...\", \"reason\": \"...\"} ],
  \"newly_broken\": [ ... ],
  \"remaining_total\": N
}"
    ]

    final_consensus [
        label="Merge: Final Consensus",
        shape=box,
        class="merge",
        fidelity="full",
        prompt="You have final audit results from both models in context: response.final_audit_opus and response.final_audit_gpt. Merge them into a definitive status.

Rules:
1. A gap is only \"verified_fixed\" if BOTH models agree it's fixed
2. If EITHER model says a gap is still present, it counts as still failing
3. Union all newly_broken items from both models

Respond with JSON (not by writing out a file):
{
  \"verified_fixed\": [ {\"area\": \"...\", \"module\": \"...\", \"description\": \"...\", \"agreed_by\": \"both|opus_only|gpt_only\"} ],
  \"still_failing\": [ {\"area\": \"...\", \"module\": \"...\", \"description\": \"...\", \"flagged_by\": \"both|opus_only|gpt_only\", \"reason\": \"...\"} ],
  \"newly_broken\": [ ... ],
  \"remaining_total\": N
}

If remaining_total == 0 (ignoring DEFERRED items), set preferred_next_label to \"Complete\".
Otherwise set preferred_next_label to \"More work needed\"."
    ]

    /*========================================================================
     * PHASE 8 — Human Gate
     *======================================================================*/

    review_gate [
        label="A) Accept & finish\nB) Push for another round",
        shape=hexagon
    ]

    /*========================================================================
     * EDGES — Serial interleaved chain
     *
     * The engine is single-path, so we interleave model audits.
     * fidelity="truncate" on audit nodes prevents cross-model anchoring.
     *======================================================================*/

    /* Phase 1: Interleaved audits (Opus then GPT) */
    start -> audit_opus
    audit_opus -> audit_gpt

    /* Phase 2: Cross-critique (GPT critiques Opus, then Opus critiques GPT) */
    audit_gpt -> critique_by_gpt
    critique_by_gpt -> critique_by_opus

    /* Phase 3: Consensus */
    critique_by_opus -> audit_consensus

    /* Phase 4: Dual triage (Opus then GPT then merge) */
    audit_consensus -> triage_opus
    triage_opus -> triage_gpt
    triage_gpt -> triage_merge

    /* Triage decision */
    triage_merge -> exit        [label="Done", condition="preferred_label=Done"]
    triage_merge -> fix_codex   [label="Fix", condition="preferred_label=Fix", weight=10]
    triage_merge -> exit        [label="Only deferred remain"]

    /* Phase 5: Multi-model implementation (sequential alternation) */
    fix_codex -> review_fix_opus
    review_fix_opus -> review_codex

    /* Implementation loop */
    review_codex -> fix_codex   [label="More fixes needed", condition="preferred_label=More fixes needed", loop_restart=true]
    review_codex -> build_check [label="Ready for build", condition="preferred_label=Ready for build"]

    /* Phase 6: Build */
    build_check -> final_audit_opus [label="Build OK", condition="outcome=success"]
    build_check -> build_fix        [label="Build failed", condition="outcome=fail"]
    build_fix -> build_check

    /* Phase 7: Dual final audit (Opus then GPT then consensus) */
    final_audit_opus -> final_audit_gpt
    final_audit_gpt -> final_consensus

    /* Final decision */
    final_consensus -> review_gate  [label="Complete", condition="preferred_label=Complete"]
    final_consensus -> triage_merge [label="More work needed", condition="preferred_label=More work needed"]

    /* Phase 8: Human gate */
    review_gate -> exit             [label="A) Accept"]
    review_gate -> triage_merge     [label="B) Another round"]
}
